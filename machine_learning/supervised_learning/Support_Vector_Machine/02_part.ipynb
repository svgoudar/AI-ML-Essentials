{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a2a4e0",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac19c00f",
   "metadata": {},
   "source": [
    "## Assumptions\n",
    "\n",
    "1. **Data is (approximately) separable**\n",
    "\n",
    "   * SVM assumes that classes can be separated by a hyperplane, either in original space (linear) or transformed space (non-linear with kernels).\n",
    "\n",
    "2. **Large-margin principle**\n",
    "\n",
    "   * Assumes that the best decision boundary is the one that maximizes margin between classes.\n",
    "\n",
    "3. **Kernel appropriateness**\n",
    "\n",
    "   * If data is non-linear, assumes the chosen kernel (RBF, polynomial, etc.) maps data to a space where separation is possible.\n",
    "\n",
    "4. **Independent and identically distributed (i.i.d.) data**\n",
    "\n",
    "   * Training and test samples come from the same distribution and are independent.\n",
    "\n",
    "5. **Balanced scaling of features**\n",
    "\n",
    "   * Assumes input features are normalized/scaled, since SVM relies on distance calculations.\n",
    "\n",
    "6. **Limited noise and outliers**\n",
    "\n",
    "   * Assumes data is not heavily noisy, since outliers close to the margin can affect the boundary.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
