{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2caa17d5",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics\n",
    "\n",
    "## **AdaBoost Classification**\n",
    "\n",
    "When using AdaBoost as a **classifier**, you evaluate how well the model separates classes. The most common metrics are:\n",
    "\n",
    "### ✅ Accuracy\n",
    "\n",
    "* Proportion of correctly classified samples.\n",
    "* Good for **balanced datasets**, but misleading for **imbalanced classes**.\n",
    "\n",
    "### ✅ Precision, Recall, and F1-Score\n",
    "\n",
    "* **Precision**: Among the predicted positives, how many are correct?\n",
    "* **Recall (Sensitivity)**: Among the actual positives, how many are captured?\n",
    "* **F1-score**: Harmonic mean of precision & recall → balances both.\n",
    "* Useful when dealing with **imbalanced datasets**.\n",
    "\n",
    "### ✅ ROC-AUC (Receiver Operating Characteristic – Area Under Curve)\n",
    "\n",
    "* Plots True Positive Rate vs False Positive Rate.\n",
    "* **AUC close to 1** → strong classifier.\n",
    "* Threshold-independent metric.\n",
    "\n",
    "### ✅ Log Loss (Cross-Entropy Loss)\n",
    "\n",
    "* Measures the **probabilistic confidence** of predictions.\n",
    "* Lower log loss = better probability calibration.\n",
    "* More informative than accuracy because it penalizes “overconfident wrong predictions.”\n",
    "\n",
    "---\n",
    "\n",
    "## **AdaBoost Regression**\n",
    "\n",
    "When AdaBoost is used with **regression trees**, you measure how well it predicts continuous values:\n",
    "\n",
    "### Mean Squared Error (MSE)\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "* Penalizes large errors more heavily.\n",
    "\n",
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{MSE}\n",
    "$$\n",
    "\n",
    "* Same units as the target variable → more interpretable.\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{n} \\sum |y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "* Less sensitive to outliers than MSE.\n",
    "\n",
    "### R² Score (Coefficient of Determination)\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}\n",
    "$$\n",
    "\n",
    "* Measures proportion of variance explained by the model.\n",
    "* $R^2 = 1$: perfect predictions,\n",
    "* $R^2 = 0$: no better than mean prediction.\n",
    "\n",
    "### Median Absolute Error\n",
    "\n",
    "* Median of absolute residuals.\n",
    "* Very robust against **outliers** compared to MSE/RMSE.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Insights**\n",
    "\n",
    "* For **classification**, use **Accuracy + Precision/Recall/F1 + AUC** depending on dataset balance.\n",
    "* For **regression**, rely on **MSE, MAE, RMSE, and R²** for error magnitude and explanatory power.\n",
    "* Since AdaBoost can **overfit noisy datasets**, monitoring multiple metrics is crucial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb508e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                         Accuracy  Precision    Recall  F1-Score   ROC-AUC  \\\n",
       " AdaBoost Classification      0.86   0.907407  0.753846  0.823529  0.956018   \n",
       " \n",
       "                          Log Loss  \n",
       " AdaBoost Classification  0.499989  ,\n",
       "                              MSE       RMSE       MAE  R2 Score  \\\n",
       " AdaBoost Regression  5842.940439  76.439129  57.97347  0.713638   \n",
       " \n",
       "                      Median Absolute Error  \n",
       " AdaBoost Regression              46.093553  )"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, log_loss, confusion_matrix, classification_report,\n",
    "    mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------\n",
    "# PART 1: CLASSIFICATION\n",
    "# -------------------------\n",
    "# Create synthetic classification dataset\n",
    "X_cls, y_cls = make_classification(\n",
    "    n_samples=500, n_features=10, n_informative=5, n_redundant=2,\n",
    "    n_classes=2, weights=[0.6, 0.4], random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_cls, y_cls, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train AdaBoost Classifier\n",
    "ada_cls = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=100, learning_rate=0.5, random_state=42\n",
    ")\n",
    "ada_cls.fit(Xc_train, yc_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_cls = ada_cls.predict(Xc_test)\n",
    "y_proba_cls = ada_cls.predict_proba(Xc_test)[:,1]\n",
    "\n",
    "# Classification metrics\n",
    "cls_metrics = {\n",
    "    \"Accuracy\": accuracy_score(yc_test, y_pred_cls),\n",
    "    \"Precision\": precision_score(yc_test, y_pred_cls),\n",
    "    \"Recall\": recall_score(yc_test, y_pred_cls),\n",
    "    \"F1-Score\": f1_score(yc_test, y_pred_cls),\n",
    "    \"ROC-AUC\": roc_auc_score(yc_test, y_proba_cls),\n",
    "    \"Log Loss\": log_loss(yc_test, y_proba_cls)\n",
    "}\n",
    "\n",
    "# -------------------------\n",
    "# PART 2: REGRESSION\n",
    "# -------------------------\n",
    "# Create synthetic regression dataset\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=500, n_features=10, noise=10.0, random_state=42\n",
    ")\n",
    "\n",
    "# Split data\n",
    "Xr_train, Xr_test, yr_train, yr_test = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train AdaBoost Regressor\n",
    "ada_reg = AdaBoostRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=3),\n",
    "    n_estimators=100, learning_rate=0.5, random_state=42\n",
    ")\n",
    "ada_reg.fit(Xr_train, yr_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_reg = ada_reg.predict(Xr_test)\n",
    "\n",
    "# Regression metrics\n",
    "reg_metrics = {\n",
    "    \"MSE\": mean_squared_error(yr_test, y_pred_reg),\n",
    "    \"RMSE\": np.sqrt(mean_squared_error(yr_test, y_pred_reg)),\n",
    "    \"MAE\": mean_absolute_error(yr_test, y_pred_reg),\n",
    "    \"R2 Score\": r2_score(yr_test, y_pred_reg),\n",
    "    \"Median Absolute Error\": median_absolute_error(yr_test, y_pred_reg)\n",
    "}\n",
    "\n",
    "import pandas as pd\n",
    "cls_df = pd.DataFrame([cls_metrics], index=[\"AdaBoost Classification\"])\n",
    "reg_df = pd.DataFrame([reg_metrics], index=[\"AdaBoost Regression\"])\n",
    "(cls_df, reg_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
