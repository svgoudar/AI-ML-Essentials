{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66a5fa74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7bb27906",
   "metadata": {},
   "source": [
    "\n",
    "# Workflows\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "* Define the task (e.g., spam detection, sentiment analysis, medical diagnosis).\n",
    "* Decide what the **input features** are (words, pixel values, categorical attributes).\n",
    "* Decide what the **target labels** are (spam/ham, positive/negative, disease/healthy).\n",
    "\n",
    "---\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "* Collect labeled data.\n",
    "* Preprocess features:\n",
    "\n",
    "  * For **text data** â†’ tokenization, stopword removal, vectorization (Bag of Words, TF-IDF).\n",
    "  * For **categorical data** â†’ encode categories into counts or frequencies.\n",
    "  * For **continuous data** â†’ assume Gaussian distribution (Gaussian NaÃ¯ve Bayes).\n",
    "* Split dataset into **train/test (or validation)** sets.\n",
    "\n",
    "---\n",
    "\n",
    "## Training (Fit)\n",
    "\n",
    "NaÃ¯ve Bayes learns probabilities from data:\n",
    "\n",
    "1. Compute **prior probabilities** for each class:\n",
    "\n",
    "   $$\n",
    "   P(y=c) = \\frac{\\text{count of class } c}{\\text{total samples}}\n",
    "   $$\n",
    "2. Compute **likelihoods** for each feature given class:\n",
    "\n",
    "   * For categorical:\n",
    "\n",
    "     $$\n",
    "     P(x_i \\mid y=c) = \\frac{\\text{count}(x_i, y=c)}{\\text{count}(y=c)}\n",
    "     $$\n",
    "   * For text: word frequencies (with Laplace smoothing).\n",
    "   * For continuous: use Gaussian distribution:\n",
    "\n",
    "     $$\n",
    "     P(x_i \\mid y=c) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x_i - \\mu)^2}{2\\sigma^2}}\n",
    "     $$\n",
    "\n",
    "---\n",
    "\n",
    "## Prediction (Inference)\n",
    "\n",
    "Given a new instance $X = (x_1, x_2, \\dots, x_n)$:\n",
    "\n",
    "1. Apply Bayes theorem:\n",
    "\n",
    "   $$\n",
    "   P(y \\mid X) \\propto P(y) \\cdot \\prod_{i=1}^n P(x_i \\mid y)\n",
    "   $$\n",
    "2. Select the class with **maximum posterior probability**:\n",
    "\n",
    "   $$\n",
    "   \\hat{y} = \\arg\\max_y P(y) \\prod_i P(x_i \\mid y)\n",
    "   $$\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "* Use metrics depending on task:\n",
    "\n",
    "  * **Classification**: Accuracy, Precision, Recall, F1-score.\n",
    "  * **Probabilistic predictions**: Log-loss, ROC-AUC.\n",
    "* Cross-validation for robustness.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Deployment\n",
    "\n",
    "* Save the trained model (priors + likelihoods).\n",
    "* For new unseen data, run through preprocessing â†’ prediction pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Spam Classification Workflow\n",
    "\n",
    "1. **Data**: Emails labeled as spam/ham.\n",
    "2. **Preprocessing**: Tokenize words â†’ convert to TF-IDF features.\n",
    "3. **Training**:\n",
    "\n",
    "   * $P(\\text{spam})$, $P(\\text{ham})$ (priors).\n",
    "   * $P(\\text{word} \\mid \\text{spam})$, $P(\\text{word} \\mid \\text{ham})$.\n",
    "4. **Prediction**: For a new email, multiply word likelihoods + prior, choose class with higher posterior.\n",
    "5. **Evaluation**: Check accuracy, precision, recall on test emails.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary Workflow**\n",
    "ðŸ‘‰ Define Problem â†’ Preprocess Data â†’ Train (estimate probabilities) â†’ Predict (posterior) â†’ Evaluate â†’ Deploy\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
