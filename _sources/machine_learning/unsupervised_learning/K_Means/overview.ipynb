{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35eef116",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "K-Means is one of the most popular **unsupervised learning** algorithms used for **clustering**.\n",
    "\n",
    "* It partitions a dataset into **K clusters** (groups).\n",
    "* Each cluster has a **centroid** (the ‚Äúcenter‚Äù of the cluster).\n",
    "* Data points are assigned to the cluster whose centroid is **closest** (based on distance, usually Euclidean).\n",
    "\n",
    "It‚Äôs like grouping students into K study groups based on how close their marks are in math and science.\n",
    "\n",
    "---\n",
    "\n",
    "## The K-Means Algorithm (Step-by-Step)\n",
    "\n",
    "1. **Choose K** ‚Üí the number of clusters you want.\n",
    "2. **Initialize centroids** ‚Üí randomly select K points as initial centroids.\n",
    "3. **Assign points to nearest centroid** ‚Üí each data point joins the cluster with the closest centroid (using Euclidean distance).\n",
    "4. **Update centroids** ‚Üí recalculate the centroid of each cluster as the mean of its points.\n",
    "5. **Repeat steps 3‚Äì4** until:\n",
    "\n",
    "   * Centroids stop changing significantly (**convergence**), or\n",
    "   * Max iterations reached.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Intuition\n",
    "\n",
    "* The **objective function** minimized by K-Means is the **Within-Cluster Sum of Squares (WCSS)**:\n",
    "\n",
    "$$\n",
    "J = \\sum_{i=1}^{K} \\sum_{x \\in C_i} \\|x - \\mu_i\\|^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $K$ = number of clusters\n",
    "* $C_i$ = set of points in cluster $i$\n",
    "* $\\mu_i$ = centroid of cluster $i$\n",
    "\n",
    "üëâ Goal: minimize distance of all points from their cluster centroids.\n",
    "\n",
    "---\n",
    "\n",
    "## Choosing the Right K (Number of Clusters)\n",
    "\n",
    "1. **Elbow Method** ‚Üí plot WCSS vs. K, look for an ‚Äúelbow‚Äù point.\n",
    "2. **Silhouette Score** ‚Üí measures how similar a point is to its own cluster vs. others.\n",
    "3. **Gap Statistics** ‚Üí compares clustering performance against random data.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "\n",
    "‚úÖ Simple and easy to implement.\n",
    "‚úÖ Works well with large datasets.\n",
    "‚úÖ Converges quickly.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "\n",
    "‚ùå Must pre-define **K**.\n",
    "‚ùå Sensitive to **initialization** (bad initial centroids ‚Üí poor results).\n",
    "‚ùå Struggles with **non-spherical clusters** or clusters of different densities.\n",
    "‚ùå Sensitive to **outliers**.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Cases\n",
    "\n",
    "* Customer segmentation in marketing.\n",
    "* Document or image clustering.\n",
    "* Anomaly detection.\n",
    "* Grouping genes with similar expression patterns in biology.\n",
    "\n",
    "---\n",
    "\n",
    "**Quick Intuition Example**:\n",
    "Imagine you have data on people‚Äôs **height and weight**. If you run K-Means with $K=3$:\n",
    "\n",
    "* Cluster 1 might group **short & light** people.\n",
    "* Cluster 2 might group **medium height & medium weight** people.\n",
    "* Cluster 3 might group **tall & heavy** people.\n",
    "\n",
    "The algorithm finds these groups automatically without labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b0c576",
   "metadata": {},
   "source": [
    "```{dropdown} Click here for Sections\n",
    "```{tableofcontents}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
