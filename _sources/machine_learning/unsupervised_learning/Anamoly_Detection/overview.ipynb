{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "168f6016",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f01c8c",
   "metadata": {},
   "source": [
    "# Anamoly Detection\n",
    "\n",
    "\n",
    "* **Anomaly detection** means identifying **outliers** in data — points that deviate significantly from normal patterns.\n",
    "* Outliers are crucial in some problems (e.g., fraud detection, security breaches, disease detection) but may be irrelevant in others.\n",
    "* **Examples**:\n",
    "\n",
    "  * Bank login from unusual locations\n",
    "  * Unusual runs scored in an IPL over\n",
    "  * Rare disease detection in healthcare datasets\n",
    "\n",
    "---\n",
    "\n",
    "## Importance of Outliers\n",
    "\n",
    "* Outliers indicate unique or abnormal events in a dataset.\n",
    "* Detecting anomalies is often **unsupervised**, as labels for anomalies are usually not available.\n",
    "* Outliers may represent critical events (fraud, disease) or noise, depending on the context.\n",
    "\n",
    "---\n",
    "\n",
    "## Isolation Forest Concept\n",
    "\n",
    "* **Isolation Forest** is an **unsupervised anomaly detection algorithm**.\n",
    "* Uses **isolation trees** (similar to decision trees) to separate individual points:\n",
    "\n",
    "  * Outliers are **isolated faster**, requiring fewer splits.\n",
    "  * Normal points require more splits to isolate.\n",
    "* The **anomaly score** is calculated using the formula:\n",
    "\n",
    "$$\n",
    "s(x, m) = 2^{-\\frac{E(h(x))}{c(m)}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $h(x)$ = average path length to isolate point $x$ in a tree\n",
    "\n",
    "* $E(h(x))$ = average path length over multiple trees\n",
    "\n",
    "* $c(m)$ = expected path length for a sample of size $m$\n",
    "\n",
    "* Points with scores close to 1 → likely anomalies.\n",
    "\n",
    "* Threshold (e.g., 0.5) is set to classify points as outliers.\n",
    "\n",
    "---\n",
    "\n",
    "## How Isolation Forest Works\n",
    "\n",
    "1. Randomly select a feature and split a value between its min and max.\n",
    "2. Recursively create nodes until each point is isolated in a leaf.\n",
    "3. Points that are isolated in **shorter paths** → anomalies.\n",
    "4. Multiple isolation trees are used for robustness.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Practical Example**\n",
    "\n",
    "* A healthcare dataset with 2 features (indicating disease) was used.\n",
    "\n",
    "* Steps:\n",
    "\n",
    "  1. Load dataset.\n",
    "  2. Fit **Isolation Forest** (`contamination` parameter defines proportion of expected anomalies).\n",
    "  3. Predict anomalies (`1` = normal, `-1` = outlier).\n",
    "  4. Visualize outliers on a scatter plot (outliers highlighted in red).\n",
    "\n",
    "* Results: Outliers were clearly separated from normal points, demonstrating Isolation Forest’s effectiveness.\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Key Points**\n",
    "\n",
    "* Anomaly detection is **unsupervised**.\n",
    "* Isolation Forest isolates data points rather than clustering.\n",
    "* Outliers are detected based on how quickly they can be separated from the rest of the data.\n",
    "* Useful for fraud detection, cybersecurity, healthcare, and other domains with rare events.\n",
    "\n",
    "\n",
    "## Statistical / Classical Methods\n",
    "\n",
    "* **Z-score / Standard Deviation**\n",
    "  Detect points that deviate from mean by > n standard deviations.\n",
    "\n",
    "* **Modified Z-score**\n",
    "  More robust to outliers using median and MAD (Median Absolute Deviation).\n",
    "\n",
    "* **Grubbs’ Test / Dixon’s Q Test**\n",
    "  Statistical tests for single outliers.\n",
    "\n",
    "* **Boxplot / IQR Method**\n",
    "  Points outside `Q1 - 1.5*IQR` or `Q3 + 1.5*IQR`.\n",
    "\n",
    "---\n",
    "\n",
    "## Distance-based Methods\n",
    "\n",
    "* **k-Nearest Neighbors (kNN) for anomaly detection**\n",
    "  Anomalies have large distances to nearest neighbors.\n",
    "\n",
    "* **Local Outlier Factor (LOF)**\n",
    "  Measures how isolated a point is compared to its neighbors.\n",
    "\n",
    "* **Mahalanobis Distance**\n",
    "  Measures distance considering correlation between features.\n",
    "\n",
    "---\n",
    "\n",
    "## Clustering-based Methods\n",
    "\n",
    "* **K-Means-based anomaly detection**\n",
    "  Points far from any cluster centroid are anomalies.\n",
    "\n",
    "* **DBSCAN**\n",
    "  Points labeled as noise (`-1`) are anomalies.\n",
    "\n",
    "* **Hierarchical clustering**\n",
    "  Small isolated clusters or singleton points can be anomalies.\n",
    "\n",
    "---\n",
    "\n",
    "## Classification / Supervised Methods\n",
    "\n",
    "*(Requires labeled data: normal vs. anomaly)*\n",
    "\n",
    "* **Support Vector Machine (SVM) – One-Class SVM**\n",
    "  Learns the boundary of normal points; points outside are anomalies.\n",
    "\n",
    "* **Random Forest / Isolation Forest**\n",
    "  Detects anomalies by isolating points that are easier to split.\n",
    "\n",
    "* **Gradient Boosting / XGBoost** (for anomaly classification if labeled)\n",
    "\n",
    "---\n",
    "\n",
    "## Neural Network / Deep Learning Methods\n",
    "\n",
    "* **Autoencoders**\n",
    "  Reconstruct input; large reconstruction error → anomaly.\n",
    "\n",
    "* **Variational Autoencoders (VAE)**\n",
    "  Probabilistic reconstruction; high likelihood deviations → anomaly.\n",
    "\n",
    "* **LSTM-based Autoencoders**\n",
    "  For **time series anomaly detection**.\n",
    "\n",
    "* **Generative Adversarial Networks (GANs)**\n",
    "  Identify anomalies as points the generator fails to reproduce well.\n",
    "\n",
    "---\n",
    "\n",
    "## Probabilistic / Density-based Methods\n",
    "\n",
    "* **Gaussian Mixture Models (GMM)**\n",
    "  Low probability points under the model are anomalies.\n",
    "\n",
    "* **Kernel Density Estimation (KDE)**\n",
    "  Points in low-density regions → anomalies.\n",
    "\n",
    "* **Bayesian Networks**\n",
    "  Probabilistic modeling to detect unusual events.\n",
    "\n",
    "---\n",
    "\n",
    "## Time-Series Specific Methods\n",
    "\n",
    "* **ARIMA / SARIMA Residuals**\n",
    "  Residuals beyond thresholds → anomaly.\n",
    "\n",
    "* **Prophet / Facebook Prophet**\n",
    "  Detect deviations from predicted trends.\n",
    "\n",
    "* **Twitter AnomalyDetection (R / Python port)**\n",
    "\n",
    "---\n",
    "\n",
    "## Ensemble Methods\n",
    "\n",
    "* Combine multiple anomaly detection models:\n",
    "\n",
    "  * Isolation Forest + LOF\n",
    "  * Autoencoder + Statistical threshold\n",
    "  * Voting / stacking ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea52a3",
   "metadata": {},
   "source": [
    "```{dropdown} Click here for Sections\n",
    "```{tableofcontents}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
