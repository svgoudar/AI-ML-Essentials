{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f52926",
   "metadata": {},
   "source": [
    "```{contents}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0b4b3",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor\n",
    "\n",
    "* A **Decision Tree Regressor** is the regression version of decision trees.\n",
    "* Instead of predicting a **class label** (like \"Iris-setosa\" or \"Iris-versicolor\"), it predicts a **continuous value** (like house price, temperature, sales).\n",
    "* The dataset is recursively split based on **features**, but instead of maximizing classification purity (Gini/Entropy), we minimize the **variance** (or mean squared error) in the target values.\n",
    "\n",
    "---\n",
    "\n",
    "## How it Works (Step by Step)\n",
    "\n",
    "1. **Start at the root node** (whole dataset).\n",
    "2. At each split:\n",
    "\n",
    "   * Choose the feature & threshold that minimizes a cost function.\n",
    "   * Common cost functions for regression:\n",
    "\n",
    "     * **Mean Squared Error (MSE)**\n",
    "\n",
    "       $$\n",
    "       MSE = \\frac{1}{n}\\sum_{i=1}^n (y_i - \\hat{y})^2\n",
    "       $$\n",
    "     * **Mean Absolute Error (MAE)**\n",
    "\n",
    "       $$\n",
    "       MAE = \\frac{1}{n}\\sum_{i=1}^n |y_i - \\hat{y}|\n",
    "       $$\n",
    "   * Here, $\\hat{y}$ is the mean (or median) of values in that node.\n",
    "3. **Split until stopping criteria** (max depth, min samples per leaf, etc.).\n",
    "4. **Prediction**: For a new sample, traverse the tree and return the **mean value of the leaf node** it falls into.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Cases\n",
    "\n",
    "* Predicting **house prices** from size, location, number of bedrooms.\n",
    "* Forecasting **stock values** (though prone to overfitting).\n",
    "* Estimating **energy consumption** from temperature & household data.\n",
    "\n",
    "---\n",
    "\n",
    "## Advantages\n",
    "\n",
    "* Simple, interpretable.\n",
    "* Captures **non-linear relationships**.\n",
    "* Handles both numerical & categorical features.\n",
    "\n",
    "---\n",
    "\n",
    "## Disadvantages\n",
    "\n",
    "* Prone to **overfitting** (deep trees fit noise).\n",
    "* Piecewise constant predictions (not smooth).\n",
    "* Sensitive to small changes in data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937a6a70",
   "metadata": {},
   "source": [
    "```{dropdown} Click here for Sections\n",
    "```{tableofcontents}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
